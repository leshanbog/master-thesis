{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "motivated-concrete",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import json\n",
    "import random\n",
    "import tqdm.notebook as tqdm\n",
    "import re\n",
    "import razdel\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abandoned-killer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from _jsonnet import evaluate_file as jsonnet_evaluate_file\n",
    "from transformers import BertTokenizer, EncoderDecoderModel, AutoModelForSequenceClassification, logging\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "from readers.ria_reader import ria_reader\n",
    "from readers.tg_reader import tg_reader\n",
    "from custom_datasets.gen_title_dataset import GenTitleDataset\n",
    "from utils.gen_title_calculate_metrics import print_metrics, first_sent, postprocess\n",
    "from utils.training_utils import init_wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-degree",
   "metadata": {},
   "source": [
    "## Using clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "charitable-twelve",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.set_verbosity_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "thousand-pakistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = json.loads(jsonnet_evaluate_file('../configs/gen_title.jsonnet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "flush-scotland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.30<br/>\n",
       "                Resuming run <strong style=\"color:#cdcd00\">TRASH</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/leshanbog/master-thesis\" target=\"_blank\">https://wandb.ai/leshanbog/master-thesis</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/leshanbog/master-thesis/runs/1d4cpfah\" target=\"_blank\">https://wandb.ai/leshanbog/master-thesis/runs/1d4cpfah</a><br/>\n",
       "                Run data is saved locally in <code>/home/aobuhtijarov/master-thesis/src/wandb/run-20210512_162714-1d4cpfah</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "init_wandb('TRASH', config, run_id='1d4cpfah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "welsh-toyota",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Didn't find file /home/aobuhtijarov/models/rubert_cased_L-12_H-768_A-12_pt/added_tokens.json. We won't load it.\n",
      "Didn't find file /home/aobuhtijarov/models/rubert_cased_L-12_H-768_A-12_pt/special_tokens_map.json. We won't load it.\n",
      "Didn't find file /home/aobuhtijarov/models/rubert_cased_L-12_H-768_A-12_pt/tokenizer_config.json. We won't load it.\n",
      "Didn't find file /home/aobuhtijarov/models/rubert_cased_L-12_H-768_A-12_pt/tokenizer.json. We won't load it.\n",
      "loading file /home/aobuhtijarov/models/rubert_cased_L-12_H-768_A-12_pt/vocab.txt\n",
      "loading file None\n",
      "loading file None\n",
      "loading file None\n",
      "loading file None\n"
     ]
    }
   ],
   "source": [
    "tokenizer_model_path = config[\"tokenizer_model_path\"]\n",
    "tokenizer = BertTokenizer.from_pretrained(tokenizer_model_path, do_lower_case=False, do_basic_tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "interested-vacuum",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model_file = '../../models/lenta_ria_cross_style_from_pretrained/checkpoint-3500/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "experienced-authentication",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens_text = config[\"max_tokens_text\"]\n",
    "max_tokens_title = config[\"max_tokens_title\"]\n",
    "setattr(tokenizer, 'max_tokens_text', max_tokens_text)\n",
    "\n",
    "batch_size = config[\"batch_size\"]\n",
    "\n",
    "# print(\"Loading model...\")\n",
    "# model = EncoderDecoderModel.from_pretrained(eval_model_file)\n",
    "# model.eval()\n",
    "# model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "excellent-technical",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def reader(path):\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            yield json.loads(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "interracial-hawaii",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66697368df6e4d4f95d2baf95f692321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "records = [r for r in tqdm.tqdm(reader('../../datasets/full_lenta_ria.test.jsonl'))]\n",
    "lenta_records = [\n",
    "    {'text': r['lenta_text'], 'title': r['lenta_title'], 'agency': 'lenta.ru', 'date': r['lenta_date']} \n",
    "    for r in records\n",
    "]\n",
    "\n",
    "ria_records = [\n",
    "    {'text': r['ria_text'], 'title': r['ria_title'], 'agency': 'РИА Новости', 'date': r['lenta_date']} \n",
    "    for r in records\n",
    "]\n",
    "records = lenta_records + ria_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "revised-fraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = GenTitleDataset(\n",
    "    records, tokenizer,\n",
    "    max_tokens_text=max_tokens_text, max_tokens_title=max_tokens_title\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaning-pipeline",
   "metadata": {},
   "source": [
    "# Style vs No style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "worse-sector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 4000\n"
     ]
    }
   ],
   "source": [
    "test_dataset = GenTitleDataset(\n",
    "    records, tokenizer,\n",
    "    max_tokens_text=max_tokens_text, max_tokens_title=max_tokens_title\n",
    ")\n",
    "\n",
    "ria_dataset = GenTitleDataset(\n",
    "    ria_records, tokenizer,\n",
    "    max_tokens_text=max_tokens_text, max_tokens_title=max_tokens_title\n",
    ")\n",
    "\n",
    "lenta_dataset = GenTitleDataset(\n",
    "    lenta_records, tokenizer,\n",
    "    max_tokens_text=max_tokens_text, max_tokens_title=max_tokens_title\n",
    ")\n",
    "\n",
    "print('Dataset size:', len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sexual-deputy",
   "metadata": {},
   "outputs": [],
   "source": [
    "agency_list = [\"РИА Новости\", \"lenta.ru\"]\n",
    "agency_to_special_token_id = {a: tokenizer.vocab[f'[unused{i+1}]'] for i, a in enumerate(agency_list)}\n",
    "agency_to_discr_target = {a: i for i, a in enumerate(sorted(agency_list))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "together-consensus",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../../models/gen_title_lenta_ria/checkpoint-6000/config.json\n",
      "Model config EncoderDecoderConfig {\n",
      "  \"architectures\": [\n",
      "    \"EncoderDecoderModel\"\n",
      "  ],\n",
      "  \"decoder\": {\n",
      "    \"_name_or_path\": \"/home/aobuhtijarov/models/pretrained_dec_6_layers\",\n",
      "    \"add_cross_attention\": true,\n",
      "    \"architectures\": [\n",
      "      \"BertModel\"\n",
      "    ],\n",
      "    \"attention_probs_dropout_prob\": 0.2,\n",
      "    \"bad_words_ids\": null,\n",
      "    \"bos_token_id\": null,\n",
      "    \"chunk_size_feed_forward\": 0,\n",
      "    \"decoder_start_token_id\": null,\n",
      "    \"directionality\": \"bidi\",\n",
      "    \"diversity_penalty\": 0.0,\n",
      "    \"do_sample\": false,\n",
      "    \"early_stopping\": false,\n",
      "    \"encoder_no_repeat_ngram_size\": 0,\n",
      "    \"eos_token_id\": null,\n",
      "    \"finetuning_task\": null,\n",
      "    \"forced_bos_token_id\": null,\n",
      "    \"forced_eos_token_id\": null,\n",
      "    \"gradient_checkpointing\": false,\n",
      "    \"hidden_act\": \"gelu\",\n",
      "    \"hidden_dropout_prob\": 0.2,\n",
      "    \"hidden_size\": 768,\n",
      "    \"id2label\": {\n",
      "      \"0\": \"LABEL_0\",\n",
      "      \"1\": \"LABEL_1\"\n",
      "    },\n",
      "    \"initializer_range\": 0.02,\n",
      "    \"intermediate_size\": 3072,\n",
      "    \"is_decoder\": true,\n",
      "    \"is_encoder_decoder\": false,\n",
      "    \"label2id\": {\n",
      "      \"LABEL_0\": 0,\n",
      "      \"LABEL_1\": 1\n",
      "    },\n",
      "    \"layer_norm_eps\": 1e-12,\n",
      "    \"length_penalty\": 1.0,\n",
      "    \"max_length\": 20,\n",
      "    \"max_position_embeddings\": 512,\n",
      "    \"min_length\": 0,\n",
      "    \"model_type\": \"bert\",\n",
      "    \"no_repeat_ngram_size\": 0,\n",
      "    \"num_attention_heads\": 12,\n",
      "    \"num_beam_groups\": 1,\n",
      "    \"num_beams\": 1,\n",
      "    \"num_hidden_layers\": 6,\n",
      "    \"num_return_sequences\": 1,\n",
      "    \"output_attentions\": false,\n",
      "    \"output_hidden_states\": false,\n",
      "    \"output_scores\": false,\n",
      "    \"pad_token_id\": 0,\n",
      "    \"pooler_fc_size\": 768,\n",
      "    \"pooler_num_attention_heads\": 12,\n",
      "    \"pooler_num_fc_layers\": 3,\n",
      "    \"pooler_size_per_head\": 128,\n",
      "    \"pooler_type\": \"first_token_transform\",\n",
      "    \"position_embedding_type\": \"absolute\",\n",
      "    \"prefix\": null,\n",
      "    \"pruned_heads\": {},\n",
      "    \"remove_invalid_values\": false,\n",
      "    \"repetition_penalty\": 1.0,\n",
      "    \"return_dict\": true,\n",
      "    \"return_dict_in_generate\": false,\n",
      "    \"sep_token_id\": null,\n",
      "    \"task_specific_params\": null,\n",
      "    \"temperature\": 1.0,\n",
      "    \"tie_encoder_decoder\": false,\n",
      "    \"tie_word_embeddings\": true,\n",
      "    \"tokenizer_class\": null,\n",
      "    \"top_k\": 50,\n",
      "    \"top_p\": 1.0,\n",
      "    \"torchscript\": false,\n",
      "    \"transformers_version\": \"4.5.0\",\n",
      "    \"type_vocab_size\": 2,\n",
      "    \"use_bfloat16\": false,\n",
      "    \"use_cache\": true,\n",
      "    \"vocab_size\": 119547\n",
      "  },\n",
      "  \"encoder\": {\n",
      "    \"_name_or_path\": \"/home/aobuhtijarov/models/pretrained_enc_8_layers\",\n",
      "    \"add_cross_attention\": false,\n",
      "    \"architectures\": [\n",
      "      \"BertModel\"\n",
      "    ],\n",
      "    \"attention_probs_dropout_prob\": 0.1,\n",
      "    \"bad_words_ids\": null,\n",
      "    \"bos_token_id\": null,\n",
      "    \"chunk_size_feed_forward\": 0,\n",
      "    \"decoder_start_token_id\": null,\n",
      "    \"directionality\": \"bidi\",\n",
      "    \"diversity_penalty\": 0.0,\n",
      "    \"do_sample\": false,\n",
      "    \"early_stopping\": false,\n",
      "    \"encoder_no_repeat_ngram_size\": 0,\n",
      "    \"eos_token_id\": null,\n",
      "    \"finetuning_task\": null,\n",
      "    \"forced_bos_token_id\": null,\n",
      "    \"forced_eos_token_id\": null,\n",
      "    \"gradient_checkpointing\": false,\n",
      "    \"hidden_act\": \"gelu\",\n",
      "    \"hidden_dropout_prob\": 0.1,\n",
      "    \"hidden_size\": 768,\n",
      "    \"id2label\": {\n",
      "      \"0\": \"LABEL_0\",\n",
      "      \"1\": \"LABEL_1\"\n",
      "    },\n",
      "    \"initializer_range\": 0.02,\n",
      "    \"intermediate_size\": 3072,\n",
      "    \"is_decoder\": false,\n",
      "    \"is_encoder_decoder\": false,\n",
      "    \"label2id\": {\n",
      "      \"LABEL_0\": 0,\n",
      "      \"LABEL_1\": 1\n",
      "    },\n",
      "    \"layer_norm_eps\": 1e-12,\n",
      "    \"length_penalty\": 1.0,\n",
      "    \"max_length\": 20,\n",
      "    \"max_position_embeddings\": 512,\n",
      "    \"min_length\": 0,\n",
      "    \"model_type\": \"bert\",\n",
      "    \"no_repeat_ngram_size\": 0,\n",
      "    \"num_attention_heads\": 12,\n",
      "    \"num_beam_groups\": 1,\n",
      "    \"num_beams\": 1,\n",
      "    \"num_hidden_layers\": 8,\n",
      "    \"num_return_sequences\": 1,\n",
      "    \"output_attentions\": false,\n",
      "    \"output_hidden_states\": false,\n",
      "    \"output_scores\": false,\n",
      "    \"pad_token_id\": 0,\n",
      "    \"pooler_fc_size\": 768,\n",
      "    \"pooler_num_attention_heads\": 12,\n",
      "    \"pooler_num_fc_layers\": 3,\n",
      "    \"pooler_size_per_head\": 128,\n",
      "    \"pooler_type\": \"first_token_transform\",\n",
      "    \"position_embedding_type\": \"absolute\",\n",
      "    \"prefix\": null,\n",
      "    \"pruned_heads\": {},\n",
      "    \"remove_invalid_values\": false,\n",
      "    \"repetition_penalty\": 1.0,\n",
      "    \"return_dict\": true,\n",
      "    \"return_dict_in_generate\": false,\n",
      "    \"sep_token_id\": null,\n",
      "    \"task_specific_params\": null,\n",
      "    \"temperature\": 1.0,\n",
      "    \"tie_encoder_decoder\": false,\n",
      "    \"tie_word_embeddings\": true,\n",
      "    \"tokenizer_class\": null,\n",
      "    \"top_k\": 50,\n",
      "    \"top_p\": 1.0,\n",
      "    \"torchscript\": false,\n",
      "    \"transformers_version\": \"4.5.0\",\n",
      "    \"type_vocab_size\": 2,\n",
      "    \"use_bfloat16\": false,\n",
      "    \"use_cache\": true,\n",
      "    \"vocab_size\": 119547\n",
      "  },\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"model_type\": \"encoder-decoder\"\n",
      "}\n",
      "\n",
      "loading weights file ../../models/gen_title_lenta_ria/checkpoint-6000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing EncoderDecoderModel.\n",
      "\n",
      "All the weights of EncoderDecoderModel were initialized from the model checkpoint at ../../models/gen_title_lenta_ria/checkpoint-6000/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use EncoderDecoderModel for predictions without further training.\n",
      "loading configuration file ../../models/lenta_ria_cross_style_from_pretrained/checkpoint-3500/config.json\n",
      "Model config EncoderDecoderConfig {\n",
      "  \"_name_or_path\": \"/home/aobuhtijarov/models/gen_title_lenta_ria/checkpoint-6000/\",\n",
      "  \"architectures\": [\n",
      "    \"EncoderDecoderModel\"\n",
      "  ],\n",
      "  \"decoder\": {\n",
      "    \"_name_or_path\": \"/home/aobuhtijarov/models/pretrained_dec_6_layers\",\n",
      "    \"add_cross_attention\": true,\n",
      "    \"architectures\": [\n",
      "      \"BertModel\"\n",
      "    ],\n",
      "    \"attention_probs_dropout_prob\": 0.2,\n",
      "    \"bad_words_ids\": null,\n",
      "    \"bos_token_id\": null,\n",
      "    \"chunk_size_feed_forward\": 0,\n",
      "    \"decoder_start_token_id\": null,\n",
      "    \"directionality\": \"bidi\",\n",
      "    \"diversity_penalty\": 0.0,\n",
      "    \"do_sample\": false,\n",
      "    \"early_stopping\": false,\n",
      "    \"encoder_no_repeat_ngram_size\": 0,\n",
      "    \"eos_token_id\": null,\n",
      "    \"finetuning_task\": null,\n",
      "    \"forced_bos_token_id\": null,\n",
      "    \"forced_eos_token_id\": null,\n",
      "    \"gradient_checkpointing\": false,\n",
      "    \"hidden_act\": \"gelu\",\n",
      "    \"hidden_dropout_prob\": 0.2,\n",
      "    \"hidden_size\": 768,\n",
      "    \"id2label\": {\n",
      "      \"0\": \"LABEL_0\",\n",
      "      \"1\": \"LABEL_1\"\n",
      "    },\n",
      "    \"initializer_range\": 0.02,\n",
      "    \"intermediate_size\": 3072,\n",
      "    \"is_decoder\": true,\n",
      "    \"is_encoder_decoder\": false,\n",
      "    \"label2id\": {\n",
      "      \"LABEL_0\": 0,\n",
      "      \"LABEL_1\": 1\n",
      "    },\n",
      "    \"layer_norm_eps\": 1e-12,\n",
      "    \"length_penalty\": 1.0,\n",
      "    \"max_length\": 20,\n",
      "    \"max_position_embeddings\": 512,\n",
      "    \"min_length\": 0,\n",
      "    \"model_type\": \"bert\",\n",
      "    \"no_repeat_ngram_size\": 0,\n",
      "    \"num_attention_heads\": 12,\n",
      "    \"num_beam_groups\": 1,\n",
      "    \"num_beams\": 1,\n",
      "    \"num_hidden_layers\": 6,\n",
      "    \"num_return_sequences\": 1,\n",
      "    \"output_attentions\": false,\n",
      "    \"output_hidden_states\": false,\n",
      "    \"output_scores\": false,\n",
      "    \"pad_token_id\": 0,\n",
      "    \"pooler_fc_size\": 768,\n",
      "    \"pooler_num_attention_heads\": 12,\n",
      "    \"pooler_num_fc_layers\": 3,\n",
      "    \"pooler_size_per_head\": 128,\n",
      "    \"pooler_type\": \"first_token_transform\",\n",
      "    \"position_embedding_type\": \"absolute\",\n",
      "    \"prefix\": null,\n",
      "    \"pruned_heads\": {},\n",
      "    \"remove_invalid_values\": false,\n",
      "    \"repetition_penalty\": 1.0,\n",
      "    \"return_dict\": true,\n",
      "    \"return_dict_in_generate\": false,\n",
      "    \"sep_token_id\": null,\n",
      "    \"task_specific_params\": null,\n",
      "    \"temperature\": 1.0,\n",
      "    \"tie_encoder_decoder\": false,\n",
      "    \"tie_word_embeddings\": true,\n",
      "    \"tokenizer_class\": null,\n",
      "    \"top_k\": 50,\n",
      "    \"top_p\": 1.0,\n",
      "    \"torchscript\": false,\n",
      "    \"transformers_version\": \"4.5.0\",\n",
      "    \"type_vocab_size\": 2,\n",
      "    \"use_bfloat16\": false,\n",
      "    \"use_cache\": true,\n",
      "    \"vocab_size\": 119547\n",
      "  },\n",
      "  \"encoder\": {\n",
      "    \"_name_or_path\": \"/home/aobuhtijarov/models/pretrained_enc_8_layers\",\n",
      "    \"add_cross_attention\": false,\n",
      "    \"architectures\": [\n",
      "      \"BertModel\"\n",
      "    ],\n",
      "    \"attention_probs_dropout_prob\": 0.1,\n",
      "    \"bad_words_ids\": null,\n",
      "    \"bos_token_id\": null,\n",
      "    \"chunk_size_feed_forward\": 0,\n",
      "    \"decoder_start_token_id\": null,\n",
      "    \"directionality\": \"bidi\",\n",
      "    \"diversity_penalty\": 0.0,\n",
      "    \"do_sample\": false,\n",
      "    \"early_stopping\": false,\n",
      "    \"encoder_no_repeat_ngram_size\": 0,\n",
      "    \"eos_token_id\": null,\n",
      "    \"finetuning_task\": null,\n",
      "    \"forced_bos_token_id\": null,\n",
      "    \"forced_eos_token_id\": null,\n",
      "    \"gradient_checkpointing\": false,\n",
      "    \"hidden_act\": \"gelu\",\n",
      "    \"hidden_dropout_prob\": 0.1,\n",
      "    \"hidden_size\": 768,\n",
      "    \"id2label\": {\n",
      "      \"0\": \"LABEL_0\",\n",
      "      \"1\": \"LABEL_1\"\n",
      "    },\n",
      "    \"initializer_range\": 0.02,\n",
      "    \"intermediate_size\": 3072,\n",
      "    \"is_decoder\": false,\n",
      "    \"is_encoder_decoder\": false,\n",
      "    \"label2id\": {\n",
      "      \"LABEL_0\": 0,\n",
      "      \"LABEL_1\": 1\n",
      "    },\n",
      "    \"layer_norm_eps\": 1e-12,\n",
      "    \"length_penalty\": 1.0,\n",
      "    \"max_length\": 20,\n",
      "    \"max_position_embeddings\": 512,\n",
      "    \"min_length\": 0,\n",
      "    \"model_type\": \"bert\",\n",
      "    \"no_repeat_ngram_size\": 0,\n",
      "    \"num_attention_heads\": 12,\n",
      "    \"num_beam_groups\": 1,\n",
      "    \"num_beams\": 1,\n",
      "    \"num_hidden_layers\": 8,\n",
      "    \"num_return_sequences\": 1,\n",
      "    \"output_attentions\": false,\n",
      "    \"output_hidden_states\": false,\n",
      "    \"output_scores\": false,\n",
      "    \"pad_token_id\": 0,\n",
      "    \"pooler_fc_size\": 768,\n",
      "    \"pooler_num_attention_heads\": 12,\n",
      "    \"pooler_num_fc_layers\": 3,\n",
      "    \"pooler_size_per_head\": 128,\n",
      "    \"pooler_type\": \"first_token_transform\",\n",
      "    \"position_embedding_type\": \"absolute\",\n",
      "    \"prefix\": null,\n",
      "    \"pruned_heads\": {},\n",
      "    \"remove_invalid_values\": false,\n",
      "    \"repetition_penalty\": 1.0,\n",
      "    \"return_dict\": true,\n",
      "    \"return_dict_in_generate\": false,\n",
      "    \"sep_token_id\": null,\n",
      "    \"task_specific_params\": null,\n",
      "    \"temperature\": 1.0,\n",
      "    \"tie_encoder_decoder\": false,\n",
      "    \"tie_word_embeddings\": true,\n",
      "    \"tokenizer_class\": null,\n",
      "    \"top_k\": 50,\n",
      "    \"top_p\": 1.0,\n",
      "    \"torchscript\": false,\n",
      "    \"transformers_version\": \"4.5.0\",\n",
      "    \"type_vocab_size\": 2,\n",
      "    \"use_bfloat16\": false,\n",
      "    \"use_cache\": true,\n",
      "    \"vocab_size\": 119547\n",
      "  },\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"model_type\": \"encoder-decoder\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file ../../models/lenta_ria_cross_style_from_pretrained/checkpoint-3500/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing EncoderDecoderModel.\n",
      "\n",
      "All the weights of EncoderDecoderModel were initialized from the model checkpoint at ../../models/lenta_ria_cross_style_from_pretrained/checkpoint-3500/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use EncoderDecoderModel for predictions without further training.\n",
      "loading configuration file /home/aobuhtijarov/models/agency_discriminator_tuned/checkpoint-4000/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/home/aobuhtijarov/master-thesis/src/bert_ft_on_tg_text/checkpoint-2000/\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.5.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file /home/aobuhtijarov/models/agency_discriminator_tuned/checkpoint-4000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /home/aobuhtijarov/models/agency_discriminator_tuned/checkpoint-4000/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "vanilla_model = EncoderDecoderModel.from_pretrained('../../models/gen_title_lenta_ria/checkpoint-6000/')\n",
    "vanilla_model.eval()\n",
    "vanilla_model.cuda()\n",
    "\n",
    "style_model = EncoderDecoderModel.from_pretrained('../../models/lenta_ria_cross_style_from_pretrained/checkpoint-3500/')\n",
    "style_model.eval()\n",
    "style_model.cuda()\n",
    "\n",
    "discriminator = AutoModelForSequenceClassification.from_pretrained(\n",
    "    '/home/aobuhtijarov/models/agency_discriminator_tuned/checkpoint-4000/'\n",
    ")\n",
    "discriminator.eval()\n",
    "discriminator.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "hundred-beast",
   "metadata": {},
   "outputs": [],
   "source": [
    "refs_ria, refs_lenta, hyps_ria, hyps_lenta = [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-capitol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "816bf39978b945368b72e442cd16a20d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('on_ria_2.txt', 'w') as f:\n",
    "    for i in tqdm.trange(0, len(ria_dataset), batch_size):\n",
    "        data = ria_dataset[i]\n",
    "        \n",
    "        for k in tuple(data.keys()):\n",
    "            if k not in ('input_ids', 'attention_mask'):\n",
    "                del data[k]\n",
    "            else:\n",
    "                data[k] = data[k].unsqueeze(0)\n",
    "\n",
    "        for j in range(i + 1, min(i + batch_size, len(test_dataset))):\n",
    "            for k in data.keys():\n",
    "                data[k] = torch.cat((data[k], test_dataset[j][k].unsqueeze(0)), dim=0)\n",
    "\n",
    "        data['input_ids'] = data['input_ids'].cuda()\n",
    "        data['attention_mask'] = data['attention_mask'].cuda()\n",
    "\n",
    "        vanilla_output_ids = vanilla_model.generate(\n",
    "            **data,\n",
    "            decoder_start_token_id=vanilla_model.config.decoder.pad_token_id,\n",
    "            min_length=7,\n",
    "            max_length=20,\n",
    "            num_beams=6\n",
    "        )\n",
    "\n",
    "        vanilla_preds = [\n",
    "            tokenizer.decode(first_sent(x, tokenizer.sep_token_id), skip_special_tokens=True) for x in vanilla_output_ids\n",
    "        ]\n",
    "        \n",
    "        style_output_ids = style_model.generate(\n",
    "            **data,\n",
    "            decoder_start_token_id=style_model.config.decoder.pad_token_id,\n",
    "            min_length=7,\n",
    "            max_length=20,\n",
    "            num_beams=6\n",
    "        )\n",
    "\n",
    "        style_preds = [\n",
    "            tokenizer.decode(first_sent(x, tokenizer.sep_token_id), skip_special_tokens=True) for x in style_output_ids\n",
    "        ]\n",
    "        \n",
    "        for j in range(i, min(i + batch_size, len(test_dataset))):\n",
    "            ria_ref = ria_dataset.get_strings(j)['title']\n",
    "            lenta_ref = lenta_dataset.get_strings(j)['title']\n",
    "            va_hyp = vanilla_preds[j-i]\n",
    "            st_hyp = style_preds[j-i]\n",
    "            \n",
    "            inp_va = tokenizer(va_hyp, \n",
    "                add_special_tokens=True, max_length=max_tokens_title,\n",
    "                padding='max_length', truncation=True\n",
    "            )\n",
    "            inp_st = tokenizer(st_hyp, \n",
    "                add_special_tokens=True, max_length=max_tokens_title,\n",
    "                padding='max_length', truncation=True\n",
    "            )\n",
    "            logits_va = discriminator(input_ids=torch.LongTensor(inp_va['input_ids']).cuda().unsqueeze(0), \n",
    "                               attention_mask=torch.LongTensor(inp_va['attention_mask']).cuda().unsqueeze(0))[0]\n",
    "            logits_st = discriminator(input_ids=torch.LongTensor(inp_st['input_ids']).cuda().unsqueeze(0), \n",
    "                               attention_mask=torch.LongTensor(inp_st['attention_mask']).cuda().unsqueeze(0))[0]            \n",
    "            va_pred = torch.argmax(logits_va).item()\n",
    "            st_pred = torch.argmax(logits_st).item()\n",
    "            \n",
    "            refs_ria.append(ria_ref)\n",
    "            refs_lenta.append(lenta_ref)\n",
    "            hyps_ria.append(va_hyp)\n",
    "            hyps_lenta.append(st_hyp)\n",
    "            \n",
    "            if not (va_pred != st_pred and \\\n",
    "                    va_pred == agency_to_discr_target['РИА Новости'] and \\\n",
    "                    min(logits_va.max().item(), logits_st.max().item()) >= 3):\n",
    "                continue\n",
    "            \n",
    "            ria_ref, va_hyp = postprocess(ria_ref, va_hyp, 'ru', is_multiple_ref=True, lower=True)\n",
    "            lenta_ref, st_hyp = postprocess(lenta_ref, st_hyp, 'ru', is_multiple_ref=True, lower=True)\n",
    "            \n",
    "            f.write('RIA text: ' + ria_dataset.get_strings(j)['text'] + '\\n\\n')\n",
    "            f.write('RIA Ref headline: ' + ria_ref[0] + '\\n')\n",
    "            f.write('Lenta Ref headline: ' + lenta_ref[0] + '\\n\\n')\n",
    "            \n",
    "            f.write('RIA Hyp headline: ' + va_hyp + '\\n')\n",
    "            f.write('Lenta Hyp headline: ' + st_hyp + '\\n')\n",
    "            \n",
    "            f.write('\\n\\n' + '-' * 50 + '\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-liquid",
   "metadata": {},
   "source": [
    "#### Cross Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-bolivia",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.gen_title_calculate_metrics import calc_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-courage",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(type(x) for x in refs_ria), set(type(x) for x in refs_lenta), set(type(x) for x in hyps_ria), set(type(x) for x in hyps_lenta), \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "freelance-steal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refs_ria = [list(x) for x in refs_ria]\n",
    "# refs_lenta = [list(x) for x in refs_lenta]\n",
    "# hyps_ria = [list(x) for x in hyps_ria]\n",
    "# hyps_lenta = [list(x) for x in hyps_lenta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "underlying-porcelain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('медведев поздравил коморовского с победой на выборах президента польши',\n",
       " 'медведев поздравил коморовского с победой на выборах',\n",
       " 'медведев поздравил коморовского с успешным проведением выборов',\n",
       " 'медведев поздравил коморовский с победой на выборах')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refs_ria[0], refs_lenta[0], hyps_ria[0], hyps_lenta[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "compound-joyce",
   "metadata": {},
   "outputs": [],
   "source": [
    "refs_ria = [x[0] for x in refs_ria]\n",
    "refs_lenta = [x[0] for x in refs_lenta]\n",
    "hyps_ria = [x[0] for x in hyps_ria]\n",
    "# hyps_lenta = [x[0] for x in hyps_lenta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-patent",
   "metadata": {},
   "outputs": [],
   "source": [
    "refs_ria = [[x] for x in refs_ria]\n",
    "refs_ria_vs_refs_lenta = calc_metrics(refs_ria, refs_lenta, language='ru')\n",
    "refs_ria_vs_hyps_ria = calc_metrics(refs_ria, hyps_ria, language='ru')\n",
    "refs_ria_vs_hyps_lenta = calc_metrics(refs_ria, hyps_lenta, language='ru')\n",
    "\n",
    "refs_lenta = [[x] for x in refs_lenta]\n",
    "refs_lenta_vs_hyps_ria = calc_metrics(refs_lenta, hyps_ria, language='ru')\n",
    "refs_lenta_vs_hyps_lenta = calc_metrics(refs_lenta, hyps_lenta, language='ru')\n",
    "\n",
    "hyps_ria = [[x] for x in hyps_ria]\n",
    "hyps_ria_vs_hyps_lenta = calc_metrics(hyps_ria, hyps_lenta, language='ru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-referral",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-interference",
   "metadata": {},
   "outputs": [],
   "source": [
    "row1 = {\n",
    "    'id': 'RefsRIA',\n",
    "    'RefsRIA': np.nan,\n",
    "    'RefsLenta': scalar_from_metrics(refs_ria_vs_refs_lenta),\n",
    "    'HypsRIA': scalar_from_metrics(refs_ria_vs_hyps_ria),\n",
    "    'HypsLenta': scalar_from_metrics(refs_ria_vs_hyps_lenta),\n",
    "}\n",
    "\n",
    "row2 = {\n",
    "    'id': 'RefsLenta', \n",
    "    'RefsRIA': np.nan,\n",
    "    'RefsLenta': np.nan,\n",
    "    'HypsRIA': scalar_from_metrics(refs_lenta_vs_hyps_ria),\n",
    "    'HypsLenta': scalar_from_metrics(refs_lenta_vs_hyps_lenta),\n",
    "}\n",
    "\n",
    "row3 = {\n",
    "    'id': 'HypsRIA',\n",
    "    'RefsRIA': np.nan,\n",
    "    'RefsLenta': np.nan,\n",
    "    'HypsRIA': np.nan,\n",
    "    'HypsLenta': scalar_from_metrics(hyps_ria_vs_hyps_lenta),\n",
    "}\n",
    "\n",
    "row4 = {\n",
    "    'id': 'HypsLenta',\n",
    "    'RefsRIA': np.nan,\n",
    "    'RefsLenta': np.nan,\n",
    "    'HypsRIA': np.nan,\n",
    "    'HypsLenta': np.nan\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-likelihood",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([len(x.split()) for x in refs_ria])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-robert",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([len(x.split()) for x in refs_lenta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-prince",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([len(x.split()) for x in hyps_ria])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-gazette",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([len(x.split()) for x in hyps_lenta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-longitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalar_from_metrics(m):\n",
    "    return (m['rl'] + m['r2'] + m['rl']) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "disabled-abuse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RefsRIA</th>\n",
       "      <th>RefsLenta</th>\n",
       "      <th>HypsRIA</th>\n",
       "      <th>HypsLenta</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RefsRIA</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RefsLenta</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HypsRIA</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HypsLenta</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           RefsRIA  RefsLenta  HypsRIA  HypsLenta\n",
       "id                                               \n",
       "RefsRIA        NaN       0.32     0.34       0.35\n",
       "RefsLenta      NaN        NaN     0.40       0.35\n",
       "HypsRIA        NaN        NaN      NaN       0.49\n",
       "HypsLenta      NaN        NaN      NaN        NaN"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['id', 'RefsRIA', 'RefsLenta', 'HypsRIA', 'HypsLenta'])\n",
    "df = df.append(row1, ignore_index=True)\n",
    "df = df.append(row2, ignore_index=True)\n",
    "df = df.append(row3, ignore_index=True)\n",
    "df = df.append(row4, ignore_index=True)\n",
    "df.index = df['id']\n",
    "df = df.drop('id', axis=1)\n",
    "df.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-sending",
   "metadata": {},
   "source": [
    "# VANILA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-investing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "common-auction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "479b0c99bd454e62a944e9a24efbbaa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hyps = []\n",
    "refs = []\n",
    "\n",
    "table = wandb.Table(columns=['Reference', 'Prediction', 'Reference processed', 'Prediction processed'])\n",
    "\n",
    "for i in tqdm.trange(0, len(test_dataset), batch_size):\n",
    "    data = test_dataset[i]\n",
    "    for k in tuple(data.keys()):\n",
    "        if k not in ('input_ids', 'attention_mask'):\n",
    "            del data[k]\n",
    "        else:\n",
    "            data[k] = data[k].unsqueeze(0)\n",
    "\n",
    "    for j in range(i + 1, min(i + batch_size, len(test_dataset))):\n",
    "        for k in data.keys():\n",
    "            data[k] = torch.cat((data[k], test_dataset[j][k].unsqueeze(0)), dim=0)\n",
    "\n",
    "    data['input_ids'] = data['input_ids'].cuda()\n",
    "    data['attention_mask'] = data['attention_mask'].cuda()\n",
    "\n",
    "    output_ids = model.generate(\n",
    "        **data,\n",
    "        decoder_start_token_id=model.config.decoder.pad_token_id,\n",
    "        min_length=7,\n",
    "        max_length=20,\n",
    "        num_beams=6\n",
    "    )\n",
    "\n",
    "    preds = [\n",
    "        tokenizer.decode(first_sent(x, tokenizer.sep_token_id), skip_special_tokens=True) for x in output_ids\n",
    "    ]\n",
    "\n",
    "    for j in range(i, min(i + batch_size, len(test_dataset))):\n",
    "        if j < 2000:\n",
    "            ref = ' s_s '.join([test_dataset.get_strings(j)['title'], \n",
    "                                test_dataset.get_strings(j + 2000)['title']])\n",
    "        else:\n",
    "            ref = ' s_s '.join([test_dataset.get_strings(j)['title'], \n",
    "                                test_dataset.get_strings(j - 2000)['title']])   \n",
    "            \n",
    "        ref = test_dataset.get_strings(j)['title']\n",
    "\n",
    "        hyp = preds[j - i]\n",
    "        \n",
    "        if j % 500 == 0:\n",
    "            ref_before = ref\n",
    "            hyp_before = hyp        \n",
    "        \n",
    "        ref, hyp = postprocess(ref, hyp, 'ru', is_multiple_ref=True, lower=True)\n",
    "        \n",
    "        refs.append(ref)\n",
    "        hyps.append(hyp)\n",
    "        \n",
    "        if j % 500 == 0:\n",
    "            table.add_data(ref_before, hyp_before, ref, hyp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "novel-cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('style.txt', 'w') as f:\n",
    "    for i in range(len(refs)):\n",
    "        \n",
    "        f.write('Ref: ' + ' s_s '.join(refs[i]) + '\\n')\n",
    "        f.write('Hyp: ' + hyps[i] + '\\n')\n",
    "        f.write('\\n\\n' + '-' * 40 + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ideal-channels",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ref: медведев поздравил коморовского с победой на выборах s_s медведев поздравил коморовского с победой на выборах президента польши\r\n",
      "Hyp: медведев поздравил коморовского с победой на выборах\r\n",
      "\r\n",
      "\r\n",
      "----------------------------------------\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 vanilla.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-control",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "amber-retreat",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.run.summary.update({'Examples': table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "surgical-cover",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'count': 4000, 'bleu': 0.4853310648776669, 'r1': 0.37826795698035687, 'r2': 0.18936949952669432, 'rl': 0.34854062601969343, 'duplicate_ngrams': {1: 0.01102777492379876, 2: 0.0003968411444898607, 3: 0.00014151610925043634, 4: 5.8139534883720933e-05}}\n"
     ]
    }
   ],
   "source": [
    "print_metrics(refs, hyps, language='ru', are_clusters_used=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "patent-distribution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 1862493<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.02MB of 0.02MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/aobuhtijarov/master-thesis/src/wandb/run-20210512_160908-1d4cpfah/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/aobuhtijarov/master-thesis/src/wandb/run-20210512_160908-1d4cpfah/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>BLEU</td><td>48.53</td></tr><tr><td>V2 ROUGE-2-F</td><td>27.28</td></tr><tr><td>Count</td><td>4000</td></tr><tr><td>Dup 2-grams</td><td>0.04</td></tr><tr><td>V2 ROUGE-1-F</td><td>47.46</td></tr><tr><td>V2 ROUGE-L-F</td><td>44.33</td></tr><tr><td>V2 BLEU</td><td>64.96</td></tr><tr><td>ROUGE-2-F</td><td>18.94</td></tr><tr><td>ROUGE-L-F</td><td>34.85</td></tr><tr><td>Dup 1-grams</td><td>1.1</td></tr><tr><td>Dup 3-grams</td><td>0.01</td></tr><tr><td>ROUGE-1-F</td><td>37.83</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">TRASH</strong>: <a href=\"https://wandb.ai/leshanbog/master-thesis/runs/1d4cpfah\" target=\"_blank\">https://wandb.ai/leshanbog/master-thesis/runs/1d4cpfah</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-dealer",
   "metadata": {},
   "source": [
    "# Direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "falling-merchant",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.set_verbosity_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "victorian-spread",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = json.loads(jsonnet_evaluate_file('../configs/gen_title.jsonnet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "connected-sheep",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_model_path = config[\"tokenizer_model_path\"]\n",
    "tokenizer = BertTokenizer.from_pretrained(tokenizer_model_path, do_lower_case=False, do_basic_tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "studied-oregon",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model_file = '../../models/gen_title_lenta_ria/checkpoint-5000/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "outdoor-happiness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    }
   ],
   "source": [
    "max_tokens_text = config[\"max_tokens_text\"]\n",
    "max_tokens_title = config[\"max_tokens_title\"]\n",
    "setattr(tokenizer, 'max_tokens_text', max_tokens_text)\n",
    "\n",
    "batch_size = config[\"batch_size\"]\n",
    "\n",
    "print(\"Loading model...\")\n",
    "model = EncoderDecoderModel.from_pretrained(eval_model_file)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eastern-chest",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def reader(path):\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            yield json.loads(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "governing-communication",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f14562abcc5d4a78961ffcd714034cd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "records = [r for r in tqdm.tqdm(reader('../../datasets/full_lenta_ria.test.jsonl'))]\n",
    "lenta_records = [\n",
    "    {'text': r['lenta_text'], 'title': r['lenta_title'], 'agency': 'lenta.ru', 'date': r['lenta_date']} \n",
    "    for r in records\n",
    "]\n",
    "\n",
    "ria_records = [\n",
    "    {'text': r['ria_text'], 'title': r['ria_title'], 'agency': 'РИА Новости', 'date': r['lenta_date']} \n",
    "    for r in records\n",
    "]\n",
    "records = lenta_records + ria_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "advance-comparison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 4000\n"
     ]
    }
   ],
   "source": [
    "test_dataset = GenTitleDataset(\n",
    "    records, tokenizer,\n",
    "    max_tokens_text=max_tokens_text, max_tokens_title=max_tokens_title\n",
    ")\n",
    "\n",
    "print('Dataset size:', len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "tamil-projector",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "integrated-processing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc4ae64f61d54036b9f61b436995c19a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hyps = []\n",
    "refs = []\n",
    "table = wandb.Table(columns=['Reference', 'Prediction', 'Reference processed', 'Prediction processed'])\n",
    "\n",
    "for i in tqdm.trange(0, len(test_dataset), batch_size):\n",
    "    data = test_dataset[i]\n",
    "    for k in tuple(data.keys()):\n",
    "        if k not in ('input_ids', 'attention_mask'):\n",
    "            del data[k]\n",
    "        else:\n",
    "            data[k] = data[k].unsqueeze(0)\n",
    "\n",
    "    for j in range(i + 1, min(i + batch_size, len(test_dataset))):\n",
    "        for k in data.keys():\n",
    "            data[k] = torch.cat((data[k], test_dataset[j][k].unsqueeze(0)), dim=0)\n",
    "\n",
    "    data['input_ids'] = data['input_ids'].cuda()\n",
    "    data['attention_mask'] = data['attention_mask'].cuda()\n",
    "\n",
    "    output_ids = model.generate(\n",
    "        **data,\n",
    "        decoder_start_token_id=model.config.decoder.pad_token_id,\n",
    "        min_length=7,\n",
    "        max_length=20,\n",
    "        num_beams=6\n",
    "    )\n",
    "\n",
    "    preds = [\n",
    "        tokenizer.decode(first_sent(x, tokenizer.sep_token_id), skip_special_tokens=True) for x in output_ids\n",
    "    ]\n",
    "\n",
    "    for j in range(i, min(i + batch_size, len(test_dataset))):\n",
    "        ref = test_dataset.get_strings(j)['title']\n",
    "        hyp = preds[j - i]\n",
    "        \n",
    "        if j % 500 == 0:\n",
    "            ref_before = ref\n",
    "            hyp_before = hyp        \n",
    "        \n",
    "        ref, hyp = postprocess(ref, hyp, 'ru', False, False, False, lower=True)\n",
    "        \n",
    "        refs.append(ref)\n",
    "        hyps.append(hyp)\n",
    "        \n",
    "        if j % 500 == 0:\n",
    "            table.add_data(ref_before, hyp_before, ref, hyp)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-elephant",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.run.summary.update({'Examples': table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "underlying-leather",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(refs, hyps, language='ru', are_clusters_used=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-outdoors",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (ref, hyp) in enumerate(zip(gold, pred)):\n",
    "\n",
    "    if i % 500 == 0:\n",
    "        ref_before = ref\n",
    "        hyp_before = hyp\n",
    "\n",
    "    if max_count is not None and i >= max_count:\n",
    "        break\n",
    "\n",
    "    ref, hyp = postprocess(ref, hyp, language, is_multiple_ref, detokenize_after, tokenize_after, lower)\n",
    "    if not hyp:\n",
    "        print(\"Empty hyp for ref: \", ref)\n",
    "        continue\n",
    "    if not ref:\n",
    "        continue\n",
    "\n",
    "    if i % 500 == 0:\n",
    "        table.add_data(ref_before, hyp_before, ref, hyp)\n",
    "\n",
    "    refs.append(ref)\n",
    "    hyps.append(hyp)\n",
    "\n",
    "if are_clusters_used:\n",
    "    wandb.run.summary.update({'Examples with multiple references': table})\n",
    "else:\n",
    "    wandb.run.summary.update({'Examples': table})\n",
    "\n",
    "print_metrics(refs, hyps, language=language, are_clusters_used=are_clusters_used)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
