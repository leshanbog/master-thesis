{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from _jsonnet import evaluate_file as jsonnet_evaluate_file\n",
    "from transformers import AutoTokenizer, EncoderDecoderModel, logging, AutoModel\n",
    "from models.bottleneck_encoder_decoder import BottleneckEncoderDecoderModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.clustering_utils import get_gold_markup, get_data_to_cluster, doc2vec_bert, calc_clustering_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_to_vector_func(text_to_vec_func, model, tokenizer):\n",
    "    if text_to_vec_func == 'bert-MeanSum':\n",
    "        return lambda doc: doc2vec_bert(doc, model, tokenizer, 'MeanSum')\n",
    "    elif text_to_vec_func == 'bert-FirstCLS':\n",
    "        return lambda doc: doc2vec_bert(doc, model, tokenizer, 'FirstCLS')\n",
    "    else:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.set_verbosity_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://huggingface.co/IlyaGusev/gen_title_tg_bottleneck_encoder/resolve/main/config.json not found in cache or force_download set to True, downloading to /data/aobuhtijarov/cache_trans/tmp1ozwje48\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26b2843caeaa4abaa4f981dc909ebf3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=690.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/IlyaGusev/gen_title_tg_bottleneck_encoder/resolve/main/config.json in cache at /data/aobuhtijarov/cache_trans/991124d78a9d7cbd22e8b0826146105684df44bb2ae45b55168b4680624bc0ac.87841bc3a554ba52cee53cb7afebef5b52689b040e8f3862468adb761234a540\n",
      "creating metadata file for /data/aobuhtijarov/cache_trans/991124d78a9d7cbd22e8b0826146105684df44bb2ae45b55168b4680624bc0ac.87841bc3a554ba52cee53cb7afebef5b52689b040e8f3862468adb761234a540\n",
      "loading configuration file https://huggingface.co/IlyaGusev/gen_title_tg_bottleneck_encoder/resolve/main/config.json from cache at /data/aobuhtijarov/cache_trans/991124d78a9d7cbd22e8b0826146105684df44bb2ae45b55168b4680624bc0ac.87841bc3a554ba52cee53cb7afebef5b52689b040e8f3862468adb761234a540\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"models/rubert\",\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.2.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://huggingface.co/IlyaGusev/gen_title_tg_bottleneck_encoder/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /data/aobuhtijarov/cache_trans/tmpgexh0id1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a820e5aea714cdf970c56adb31f0e5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=711495111.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/IlyaGusev/gen_title_tg_bottleneck_encoder/resolve/main/pytorch_model.bin in cache at /data/aobuhtijarov/cache_trans/b5b81398e41ba89668795bb85714d36bd544706c0d81dcb156bc174f71a7796e.f5e27d4e7fe6b73df075ea388c6e299caf1fb05d849335f1e7160326c7b5c682\n",
      "creating metadata file for /data/aobuhtijarov/cache_trans/b5b81398e41ba89668795bb85714d36bd544706c0d81dcb156bc174f71a7796e.f5e27d4e7fe6b73df075ea388c6e299caf1fb05d849335f1e7160326c7b5c682\n",
      "loading weights file https://huggingface.co/IlyaGusev/gen_title_tg_bottleneck_encoder/resolve/main/pytorch_model.bin from cache at /data/aobuhtijarov/cache_trans/b5b81398e41ba89668795bb85714d36bd544706c0d81dcb156bc174f71a7796e.f5e27d4e7fe6b73df075ea388c6e299caf1fb05d849335f1e7160326c7b5c682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to load weights from pytorch checkpoint file for 'IlyaGusev/gen_title_tg_bottleneck_encoder' at '/data/aobuhtijarov/cache_trans/b5b81398e41ba89668795bb85714d36bd544706c0d81dcb156bc174f71a7796e.f5e27d4e7fe6b73df075ea388c6e299caf1fb05d849335f1e7160326c7b5c682'If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m                 \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_archive_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name_or_buffer)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: version_ <= kMaxSupportedFileFormatVersion INTERNAL ASSERT FAILED at /pytorch/caffe2/serialize/inline_container.cc:132, please report a bug to PyTorch. Attempted to read a PyTorch file with version 3, but the maximum supported version for reading is 2. Your PyTorch installation may be too old. (init at /pytorch/caffe2/serialize/inline_container.cc:132)\nframe #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x33 (0x7ff9ef43a193 in /usr/local/lib/python3.6/dist-packages/torch/lib/libc10.so)\nframe #1: caffe2::serialize::PyTorchStreamReader::init() + 0x1f5b (0x7ff91e3369eb in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch.so)\nframe #2: caffe2::serialize::PyTorchStreamReader::PyTorchStreamReader(std::string const&) + 0x64 (0x7ff91e337c04 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch.so)\nframe #3: <unknown function> + 0x6c53a6 (0x7ff9662673a6 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_python.so)\nframe #4: <unknown function> + 0x2961c4 (0x7ff965e381c4 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_python.so)\nframe #5: _PyCFunction_FastCallDict + 0x35c (0x566bbc in /usr/bin/python3)\nframe #6: /usr/bin/python3() [0x594a71]\nframe #7: /usr/bin/python3() [0x54a035]\nframe #8: /usr/bin/python3() [0x5515c1]\nframe #9: _PyObject_FastCallKeywords + 0x19c (0x5a9dac in /usr/bin/python3)\nframe #10: /usr/bin/python3() [0x50a433]\nframe #11: _PyEval_EvalFrameDefault + 0x444 (0x50beb4 in /usr/bin/python3)\nframe #12: /usr/bin/python3() [0x507be4]\nframe #13: _PyFunction_FastCallDict + 0x2e2 (0x508ec2 in /usr/bin/python3)\nframe #14: /usr/bin/python3() [0x594a01]\nframe #15: /usr/bin/python3() [0x549e8f]\nframe #16: /usr/bin/python3() [0x5515c1]\nframe #17: _PyObject_FastCallKeywords + 0x19c (0x5a9dac in /usr/bin/python3)\nframe #18: /usr/bin/python3() [0x50a433]\nframe #19: _PyEval_EvalFrameDefault + 0x444 (0x50beb4 in /usr/bin/python3)\nframe #20: /usr/bin/python3() [0x507be4]\nframe #21: /usr/bin/python3() [0x509900]\nframe #22: /usr/bin/python3() [0x50a2fd]\nframe #23: _PyEval_EvalFrameDefault + 0x1226 (0x50cc96 in /usr/bin/python3)\nframe #24: /usr/bin/python3() [0x507be4]\nframe #25: _PyFunction_FastCallDict + 0x2e2 (0x508ec2 in /usr/bin/python3)\nframe #26: /usr/bin/python3() [0x594a01]\nframe #27: PyObject_Call + 0x3e (0x59fd0e in /usr/bin/python3)\nframe #28: _PyEval_EvalFrameDefault + 0x17e6 (0x50d256 in /usr/bin/python3)\nframe #29: /usr/bin/python3() [0x507be4]\nframe #30: /usr/bin/python3() [0x509900]\nframe #31: /usr/bin/python3() [0x50a2fd]\nframe #32: _PyEval_EvalFrameDefault + 0x1226 (0x50cc96 in /usr/bin/python3)\nframe #33: /usr/bin/python3() [0x507be4]\nframe #34: /usr/bin/python3() [0x5161c5]\nframe #35: /usr/bin/python3() [0x50a12f]\nframe #36: _PyEval_EvalFrameDefault + 0x444 (0x50beb4 in /usr/bin/python3)\nframe #37: /usr/bin/python3() [0x58e2da]\nframe #38: _PyEval_EvalFrameDefault + 0x19dc (0x50d44c in /usr/bin/python3)\nframe #39: /usr/bin/python3() [0x58e2da]\nframe #40: _PyEval_EvalFrameDefault + 0x19dc (0x50d44c in /usr/bin/python3)\nframe #41: /usr/bin/python3() [0x58e2da]\nframe #42: /usr/bin/python3() [0x50a1cc]\nframe #43: _PyEval_EvalFrameDefault + 0x444 (0x50beb4 in /usr/bin/python3)\nframe #44: /usr/bin/python3() [0x5095c8]\nframe #45: /usr/bin/python3() [0x50a2fd]\nframe #46: _PyEval_EvalFrameDefault + 0x444 (0x50beb4 in /usr/bin/python3)\nframe #47: /usr/bin/python3() [0x5095c8]\nframe #48: /usr/bin/python3() [0x50a2fd]\nframe #49: _PyEval_EvalFrameDefault + 0x444 (0x50beb4 in /usr/bin/python3)\nframe #50: /usr/bin/python3() [0x507be4]\nframe #51: _PyFunction_FastCallDict + 0x2e2 (0x508ec2 in /usr/bin/python3)\nframe #52: /usr/bin/python3() [0x594a01]\nframe #53: PyObject_Call + 0x3e (0x59fd0e in /usr/bin/python3)\nframe #54: _PyEval_EvalFrameDefault + 0x17e6 (0x50d256 in /usr/bin/python3)\nframe #55: /usr/bin/python3() [0x507be4]\nframe #56: /usr/bin/python3() [0x509900]\nframe #57: /usr/bin/python3() [0x50a2fd]\nframe #58: _PyEval_EvalFrameDefault + 0x1226 (0x50cc96 in /usr/bin/python3)\nframe #59: /usr/bin/python3() [0x58e6f9]\nframe #60: /usr/bin/python3() [0x513a7f]\nframe #61: /usr/bin/python3() [0x50a12f]\nframe #62: _PyEval_EvalFrameDefault + 0x444 (0x50beb4 in /usr/bin/python3)\nframe #63: /usr/bin/python3() [0x507be4]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-52e24854c824>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"IlyaGusev/gen_title_tg_bottleneck_encoder\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/data/aobuhtijarov/cache_trans'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/models/auto/modeling_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMODEL_MAPPING\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m             return MODEL_MAPPING[type(config)].from_pretrained(\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             )\n\u001b[1;32m    731\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m                 raise OSError(\n\u001b[0;32m-> 1041\u001b[0;31m                     \u001b[0;34mf\"Unable to load weights from pytorch checkpoint file for '{pretrained_model_name_or_path}' \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                     \u001b[0;34mf\"at '{resolved_archive_file}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m                     \u001b[0;34m\"If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to load weights from pytorch checkpoint file for 'IlyaGusev/gen_title_tg_bottleneck_encoder' at '/data/aobuhtijarov/cache_trans/b5b81398e41ba89668795bb85714d36bd544706c0d81dcb156bc174f71a7796e.f5e27d4e7fe6b73df075ea388c6e299caf1fb05d849335f1e7160326c7b5c682'If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True. "
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "  \n",
    "model = AutoModel.from_pretrained(\"IlyaGusev/gen_title_tg_bottleneck_encoder\", cache_dir='/data/aobuhtijarov/cache_trans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/IlyaGusev/gen_title_tg_bottleneck/resolve/main/config.json from cache at /data/aobuhtijarov/cache_trans/b69815ec1afbafe51db26fe35235e17d0a6b1637b729d7ead485eb65272cf172.339b64342cafb807be8ba7e2c3c5517f97dee1f06d5eb5d39639bca5324966b4\n",
      "Model config EncoderDecoderConfig {\n",
      "  \"_name_or_path\": \"models/gen_title\",\n",
      "  \"architectures\": [\n",
      "    \"BottleneckEncoderDecoderModel\"\n",
      "  ],\n",
      "  \"decoder\": {\n",
      "    \"_name_or_path\": \"models/rubert\",\n",
      "    \"add_cross_attention\": true,\n",
      "    \"architectures\": null,\n",
      "    \"attention_probs_dropout_prob\": 0.1,\n",
      "    \"bad_words_ids\": null,\n",
      "    \"bos_token_id\": null,\n",
      "    \"chunk_size_feed_forward\": 0,\n",
      "    \"decoder_start_token_id\": null,\n",
      "    \"directionality\": \"bidi\",\n",
      "    \"diversity_penalty\": 0.0,\n",
      "    \"do_sample\": false,\n",
      "    \"early_stopping\": false,\n",
      "    \"eos_token_id\": null,\n",
      "    \"finetuning_task\": null,\n",
      "    \"gradient_checkpointing\": false,\n",
      "    \"hidden_act\": \"gelu\",\n",
      "    \"hidden_dropout_prob\": 0.1,\n",
      "    \"hidden_size\": 768,\n",
      "    \"id2label\": {\n",
      "      \"0\": \"LABEL_0\",\n",
      "      \"1\": \"LABEL_1\"\n",
      "    },\n",
      "    \"initializer_range\": 0.02,\n",
      "    \"intermediate_size\": 3072,\n",
      "    \"is_decoder\": true,\n",
      "    \"is_encoder_decoder\": false,\n",
      "    \"label2id\": {\n",
      "      \"LABEL_0\": 0,\n",
      "      \"LABEL_1\": 1\n",
      "    },\n",
      "    \"layer_norm_eps\": 1e-12,\n",
      "    \"length_penalty\": 1.0,\n",
      "    \"max_length\": 20,\n",
      "    \"max_position_embeddings\": 512,\n",
      "    \"min_length\": 0,\n",
      "    \"model_type\": \"bert\",\n",
      "    \"no_repeat_ngram_size\": 0,\n",
      "    \"num_attention_heads\": 12,\n",
      "    \"num_beam_groups\": 1,\n",
      "    \"num_beams\": 1,\n",
      "    \"num_hidden_layers\": 12,\n",
      "    \"num_return_sequences\": 1,\n",
      "    \"output_attentions\": false,\n",
      "    \"output_hidden_states\": false,\n",
      "    \"output_scores\": false,\n",
      "    \"pad_token_id\": 0,\n",
      "    \"pooler_fc_size\": 768,\n",
      "    \"pooler_num_attention_heads\": 12,\n",
      "    \"pooler_num_fc_layers\": 3,\n",
      "    \"pooler_size_per_head\": 128,\n",
      "    \"pooler_type\": \"first_token_transform\",\n",
      "    \"position_embedding_type\": \"absolute\",\n",
      "    \"prefix\": null,\n",
      "    \"pruned_heads\": {},\n",
      "    \"repetition_penalty\": 1.0,\n",
      "    \"return_dict\": false,\n",
      "    \"return_dict_in_generate\": false,\n",
      "    \"sep_token_id\": null,\n",
      "    \"task_specific_params\": null,\n",
      "    \"temperature\": 1.0,\n",
      "    \"tie_encoder_decoder\": false,\n",
      "    \"tie_word_embeddings\": true,\n",
      "    \"tokenizer_class\": null,\n",
      "    \"top_k\": 50,\n",
      "    \"top_p\": 1.0,\n",
      "    \"torchscript\": false,\n",
      "    \"transformers_version\": \"4.2.2\",\n",
      "    \"type_vocab_size\": 2,\n",
      "    \"use_bfloat16\": false,\n",
      "    \"use_cache\": true,\n",
      "    \"vocab_size\": 119547,\n",
      "    \"xla_device\": null\n",
      "  },\n",
      "  \"encoder\": {\n",
      "    \"_name_or_path\": \"models/rubert\",\n",
      "    \"add_cross_attention\": false,\n",
      "    \"architectures\": null,\n",
      "    \"attention_probs_dropout_prob\": 0.1,\n",
      "    \"bad_words_ids\": null,\n",
      "    \"bos_token_id\": null,\n",
      "    \"chunk_size_feed_forward\": 0,\n",
      "    \"decoder_start_token_id\": null,\n",
      "    \"directionality\": \"bidi\",\n",
      "    \"diversity_penalty\": 0.0,\n",
      "    \"do_sample\": false,\n",
      "    \"early_stopping\": false,\n",
      "    \"eos_token_id\": null,\n",
      "    \"finetuning_task\": null,\n",
      "    \"gradient_checkpointing\": false,\n",
      "    \"hidden_act\": \"gelu\",\n",
      "    \"hidden_dropout_prob\": 0.1,\n",
      "    \"hidden_size\": 768,\n",
      "    \"id2label\": {\n",
      "      \"0\": \"LABEL_0\",\n",
      "      \"1\": \"LABEL_1\"\n",
      "    },\n",
      "    \"initializer_range\": 0.02,\n",
      "    \"intermediate_size\": 3072,\n",
      "    \"is_decoder\": false,\n",
      "    \"is_encoder_decoder\": false,\n",
      "    \"label2id\": {\n",
      "      \"LABEL_0\": 0,\n",
      "      \"LABEL_1\": 1\n",
      "    },\n",
      "    \"layer_norm_eps\": 1e-12,\n",
      "    \"length_penalty\": 1.0,\n",
      "    \"max_length\": 20,\n",
      "    \"max_position_embeddings\": 512,\n",
      "    \"min_length\": 0,\n",
      "    \"model_type\": \"bert\",\n",
      "    \"no_repeat_ngram_size\": 0,\n",
      "    \"num_attention_heads\": 12,\n",
      "    \"num_beam_groups\": 1,\n",
      "    \"num_beams\": 1,\n",
      "    \"num_hidden_layers\": 12,\n",
      "    \"num_return_sequences\": 1,\n",
      "    \"output_attentions\": false,\n",
      "    \"output_hidden_states\": false,\n",
      "    \"output_scores\": false,\n",
      "    \"pad_token_id\": 0,\n",
      "    \"pooler_fc_size\": 768,\n",
      "    \"pooler_num_attention_heads\": 12,\n",
      "    \"pooler_num_fc_layers\": 3,\n",
      "    \"pooler_size_per_head\": 128,\n",
      "    \"pooler_type\": \"first_token_transform\",\n",
      "    \"position_embedding_type\": \"absolute\",\n",
      "    \"prefix\": null,\n",
      "    \"pruned_heads\": {},\n",
      "    \"repetition_penalty\": 1.0,\n",
      "    \"return_dict\": false,\n",
      "    \"return_dict_in_generate\": false,\n",
      "    \"sep_token_id\": null,\n",
      "    \"task_specific_params\": null,\n",
      "    \"temperature\": 1.0,\n",
      "    \"tie_encoder_decoder\": false,\n",
      "    \"tie_word_embeddings\": true,\n",
      "    \"tokenizer_class\": null,\n",
      "    \"top_k\": 50,\n",
      "    \"top_p\": 1.0,\n",
      "    \"torchscript\": false,\n",
      "    \"transformers_version\": \"4.2.2\",\n",
      "    \"type_vocab_size\": 2,\n",
      "    \"use_bfloat16\": false,\n",
      "    \"use_cache\": true,\n",
      "    \"vocab_size\": 119547,\n",
      "    \"xla_device\": null\n",
      "  },\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"model_type\": \"encoder-decoder\"\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/IlyaGusev/gen_title_tg_bottleneck/resolve/main/pytorch_model.bin from cache at /data/aobuhtijarov/cache_trans/90a823a53956d3e5bb62e88073be6a368b0d12887b8b65ea2c0f3a6e5a46b161.44bcad3a2d7e657e2170e7b929c77bf23bed7e28ee7f8a98f3f1de6a6d8b1611\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to load weights from pytorch checkpoint file for 'IlyaGusev/gen_title_tg_bottleneck' at '/data/aobuhtijarov/cache_trans/90a823a53956d3e5bb62e88073be6a368b0d12887b8b65ea2c0f3a6e5a46b161.44bcad3a2d7e657e2170e7b929c77bf23bed7e28ee7f8a98f3f1de6a6d8b1611'If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m                 \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_archive_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name_or_buffer)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: version_ <= kMaxSupportedFileFormatVersion INTERNAL ASSERT FAILED at /pytorch/caffe2/serialize/inline_container.cc:132, please report a bug to PyTorch. Attempted to read a PyTorch file with version 3, but the maximum supported version for reading is 2. Your PyTorch installation may be too old. (init at /pytorch/caffe2/serialize/inline_container.cc:132)\nframe #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x33 (0x7fb12f1a3193 in /usr/local/lib/python3.6/dist-packages/torch/lib/libc10.so)\nframe #1: caffe2::serialize::PyTorchStreamReader::init() + 0x1f5b (0x7fb05cc369eb in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch.so)\nframe #2: caffe2::serialize::PyTorchStreamReader::PyTorchStreamReader(std::string const&) + 0x64 (0x7fb05cc37c04 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch.so)\nframe #3: <unknown function> + 0x6c53a6 (0x7fb125e5b3a6 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_python.so)\nframe #4: <unknown function> + 0x2961c4 (0x7fb125a2c1c4 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_python.so)\nframe #5: _PyCFunction_FastCallDict + 0x35c (0x566bbc in /usr/bin/python3)\nframe #6: /usr/bin/python3() [0x594a71]\nframe #7: /usr/bin/python3() [0x54a035]\nframe #8: /usr/bin/python3() [0x5515c1]\nframe #9: _PyObject_FastCallKeywords + 0x19c (0x5a9dac in /usr/bin/python3)\nframe #10: /usr/bin/python3() [0x50a433]\nframe #11: _PyEval_EvalFrameDefault + 0x444 (0x50beb4 in /usr/bin/python3)\nframe #12: /usr/bin/python3() [0x507be4]\nframe #13: _PyFunction_FastCallDict + 0x2e2 (0x508ec2 in /usr/bin/python3)\nframe #14: /usr/bin/python3() [0x594a01]\nframe #15: /usr/bin/python3() [0x549e8f]\nframe #16: /usr/bin/python3() [0x5515c1]\nframe #17: _PyObject_FastCallKeywords + 0x19c (0x5a9dac in /usr/bin/python3)\nframe #18: /usr/bin/python3() [0x50a433]\nframe #19: _PyEval_EvalFrameDefault + 0x444 (0x50beb4 in /usr/bin/python3)\nframe #20: /usr/bin/python3() [0x507be4]\nframe #21: /usr/bin/python3() [0x509900]\nframe #22: /usr/bin/python3() [0x50a2fd]\nframe #23: _PyEval_EvalFrameDefault + 0x1226 (0x50cc96 in /usr/bin/python3)\nframe #24: /usr/bin/python3() [0x507be4]\nframe #25: /usr/bin/python3() [0x509900]\nframe #26: /usr/bin/python3() [0x50a2fd]\nframe #27: _PyEval_EvalFrameDefault + 0x1226 (0x50cc96 in /usr/bin/python3)\nframe #28: /usr/bin/python3() [0x507be4]\nframe #29: /usr/bin/python3() [0x5161c5]\nframe #30: /usr/bin/python3() [0x50a12f]\nframe #31: _PyEval_EvalFrameDefault + 0x444 (0x50beb4 in /usr/bin/python3)\nframe #32: /usr/bin/python3() [0x58e2da]\nframe #33: _PyEval_EvalFrameDefault + 0x19dc (0x50d44c in /usr/bin/python3)\nframe #34: /usr/bin/python3() [0x58e2da]\nframe #35: _PyEval_EvalFrameDefault + 0x19dc (0x50d44c in /usr/bin/python3)\nframe #36: /usr/bin/python3() [0x58e2da]\nframe #37: /usr/bin/python3() [0x50a1cc]\nframe #38: _PyEval_EvalFrameDefault + 0x444 (0x50beb4 in /usr/bin/python3)\nframe #39: /usr/bin/python3() [0x5095c8]\nframe #40: /usr/bin/python3() [0x50a2fd]\nframe #41: _PyEval_EvalFrameDefault + 0x444 (0x50beb4 in /usr/bin/python3)\nframe #42: /usr/bin/python3() [0x5095c8]\nframe #43: /usr/bin/python3() [0x50a2fd]\nframe #44: _PyEval_EvalFrameDefault + 0x444 (0x50beb4 in /usr/bin/python3)\nframe #45: /usr/bin/python3() [0x507be4]\nframe #46: _PyFunction_FastCallDict + 0x2e2 (0x508ec2 in /usr/bin/python3)\nframe #47: /usr/bin/python3() [0x594a01]\nframe #48: PyObject_Call + 0x3e (0x59fd0e in /usr/bin/python3)\nframe #49: _PyEval_EvalFrameDefault + 0x17e6 (0x50d256 in /usr/bin/python3)\nframe #50: /usr/bin/python3() [0x507be4]\nframe #51: /usr/bin/python3() [0x509900]\nframe #52: /usr/bin/python3() [0x50a2fd]\nframe #53: _PyEval_EvalFrameDefault + 0x1226 (0x50cc96 in /usr/bin/python3)\nframe #54: /usr/bin/python3() [0x58e6f9]\nframe #55: /usr/bin/python3() [0x513a7f]\nframe #56: /usr/bin/python3() [0x50a12f]\nframe #57: _PyEval_EvalFrameDefault + 0x444 (0x50beb4 in /usr/bin/python3)\nframe #58: /usr/bin/python3() [0x507be4]\nframe #59: /usr/bin/python3() [0x509900]\nframe #60: /usr/bin/python3() [0x50a2fd]\nframe #61: _PyEval_EvalFrameDefault + 0x444 (0x50beb4 in /usr/bin/python3)\nframe #62: /usr/bin/python3() [0x58e6f9]\nframe #63: /usr/bin/python3() [0x513a7f]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-79accacc38b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBottleneckEncoderDecoderModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'IlyaGusev/gen_title_tg_bottleneck'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/data/aobuhtijarov/cache_trans'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m                 raise OSError(\n\u001b[0;32m-> 1041\u001b[0;31m                     \u001b[0;34mf\"Unable to load weights from pytorch checkpoint file for '{pretrained_model_name_or_path}' \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                     \u001b[0;34mf\"at '{resolved_archive_file}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m                     \u001b[0;34m\"If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to load weights from pytorch checkpoint file for 'IlyaGusev/gen_title_tg_bottleneck' at '/data/aobuhtijarov/cache_trans/90a823a53956d3e5bb62e88073be6a368b0d12887b8b65ea2c0f3a6e5a46b161.44bcad3a2d7e657e2170e7b929c77bf23bed7e28ee7f8a98f3f1de6a6d8b1611'If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True. "
     ]
    }
   ],
   "source": [
    "model = BottleneckEncoderDecoderModel.from_pretrained('IlyaGusev/gen_title_tg_bottleneck', cache_dir='/data/aobuhtijarov/cache_trans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_markup_file = '/data/aobuhtijarov/datasets/telegram_news/ru_pairs_raw_markup.tsv'\n",
    "clustering_data_file = '/data/aobuhtijarov/datasets/telegram_news/ru_clustering_data.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /data/aobuhtijarov/models/rubert_cased_L-12_H-768_A-12_pt/config.json\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.2.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "Model name '/data/aobuhtijarov/models/rubert_cased_L-12_H-768_A-12_pt/' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming '/data/aobuhtijarov/models/rubert_cased_L-12_H-768_A-12_pt/' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "Didn't find file /data/aobuhtijarov/models/rubert_cased_L-12_H-768_A-12_pt/tokenizer.json. We won't load it.\n",
      "Didn't find file /data/aobuhtijarov/models/rubert_cased_L-12_H-768_A-12_pt/added_tokens.json. We won't load it.\n",
      "Didn't find file /data/aobuhtijarov/models/rubert_cased_L-12_H-768_A-12_pt/special_tokens_map.json. We won't load it.\n",
      "Didn't find file /data/aobuhtijarov/models/rubert_cased_L-12_H-768_A-12_pt/tokenizer_config.json. We won't load it.\n",
      "loading file /data/aobuhtijarov/models/rubert_cased_L-12_H-768_A-12_pt/vocab.txt\n",
      "loading file None\n",
      "loading file None\n",
      "loading file None\n",
      "loading file None\n"
     ]
    }
   ],
   "source": [
    "### BEWARE\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('/data/aobuhtijarov/models/rubert_cased_L-12_H-768_A-12_pt/', do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens_text=196\n",
    "text_to_vec_func='bert-FirstCLS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-d38617d6d33e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0murl2record\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename2url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_to_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclustering_data_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max_tokens_text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tokens_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtext_to_vector_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_text_to_vector_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_to_vec_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calculating embeddings...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "gold_markup = get_gold_markup(gold_markup_file)\n",
    "url2record, filename2url = get_data_to_cluster(clustering_data_file)\n",
    "setattr(tokenizer, 'max_tokens_text', max_tokens_text)\n",
    "text_to_vector_func = get_text_to_vector_func(text_to_vec_func, model, tokenizer)\n",
    "\n",
    "print('Calculating embeddings...')\n",
    "embeds = np.zeros((len(url2record.items()), 768))\n",
    "\n",
    "for i, (url, record) in tqdm.tqdm(enumerate(url2record.items())):\n",
    "    text = record[\"title\"] + ' ' + record[\"text\"]\n",
    "    text = text.lower().replace('\\xa0', ' ')\n",
    "    embeds[i] = text_to_vector_func(text).detach().numpy().ravel()\n",
    "\n",
    "print('Embeds shape =', embeds.shape)\n",
    "assert len(embeds) == len(url2record.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
