{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sharp-fitness",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import random\n",
    "import tqdm\n",
    "import torch\n",
    "import wandb\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from transformers import BertTokenizer, AutoModelForSequenceClassification, logging\n",
    "from custom_datasets import LentaRiaDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "billion-homework",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_path = '/home/aobuhtijarov/models/rubert_cased_L-12_H-768_A-12_pt/'\n",
    "discriminator_path = '/home/aobuhtijarov/models/discriminator_on_clusters_from_rubert/'\n",
    "paired_discr_path = '/home/aobuhtijarov/models/paired_clf_from_rubert/checkpoint-5000/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "subject-resident",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(tokenizer_path, do_lower_case=False, do_basic_tokenize=False)\n",
    "\n",
    "discriminator = AutoModelForSequenceClassification.from_pretrained(discriminator_path,\n",
    "                                                                   num_labels=2, output_attentions=True)\n",
    "discriminator.eval()\n",
    "discriminator.cuda()\n",
    "\n",
    "paired_discriminator = AutoModelForSequenceClassification.from_pretrained(paired_discr_path,\n",
    "                                                                          num_labels=2, output_attentions=True)\n",
    "paired_discriminator.eval()\n",
    "paired_discriminator.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "vietnamese-sample",
   "metadata": {},
   "outputs": [],
   "source": [
    "agency_list = [\"РИА Новости\", \"lenta.ru\"]\n",
    "agency_to_special_token_id = {a: tokenizer.vocab[f'[unused{i+1}]'] for i, a in enumerate(agency_list)}\n",
    "agency_to_discr_target = {a: i for i, a in enumerate(sorted(agency_list))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "administrative-hometown",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [00:00, 5565.62it/s]\n"
     ]
    }
   ],
   "source": [
    "def reader(path):\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            yield json.loads(line.strip())\n",
    "            \n",
    "            \n",
    "records = [r for r in tqdm.tqdm(reader('../../datasets/full_lenta_ria.test.jsonl'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "above-joyce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ria_style_headlines = [r['ria_title'] for r in records]\n",
    "lenta_style_headlines = [r['lenta_title'] for r in records]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "anticipated-behavior",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'HARD'\n",
    "mode = 'SOFT'\n",
    "\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "premier-inspection",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:04<00:00, 31.01it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    paired_discr_ok = 0\n",
    "    disc_ok = 0\n",
    "    \n",
    "    for ria_title, lenta_title in tqdm.tqdm(zip(ria_style_headlines, lenta_style_headlines), \n",
    "                                            total=len(ria_style_headlines)):            \n",
    "        inputs_0 = tokenizer(\n",
    "            ' [SEP] '.join([lenta_title, ria_title]),\n",
    "            add_special_tokens=True,\n",
    "            max_length=100,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True\n",
    "        )\n",
    "        \n",
    "        inputs_1 = tokenizer(\n",
    "            ' [SEP] '.join([ria_title, lenta_title]),\n",
    "            add_special_tokens=True,\n",
    "            max_length=100,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True\n",
    "        )\n",
    "        \n",
    "        # Paired discr\n",
    "        logits_0 = paired_discriminator(input_ids=torch.LongTensor(inputs_0['input_ids']).to(device).unsqueeze(0), \n",
    "                               attention_mask=torch.LongTensor(inputs_0['attention_mask']).to(device).unsqueeze(0))[0]\n",
    "        pred_0 = torch.argmax(logits_0).item()\n",
    "        \n",
    "        logits_1 = paired_discriminator(input_ids=torch.LongTensor(inputs_1['input_ids']).to(device).unsqueeze(0), \n",
    "                               attention_mask=torch.LongTensor(inputs_1['attention_mask']).to(device).unsqueeze(0))[0]\n",
    "        pred_1 = torch.argmax(logits_1).item()\n",
    "        \n",
    "        paired_discr_ok += int(pred_0 == 0 and pred_1 == 1)\n",
    "        \n",
    "        # Vanilla discr\n",
    "        inputs_ria = tokenizer(\n",
    "            ria_title,\n",
    "            add_special_tokens=True,\n",
    "            max_length=48,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True\n",
    "        )\n",
    "        \n",
    "        inputs_lenta = tokenizer(\n",
    "            lenta_title,\n",
    "            add_special_tokens=True,\n",
    "            max_length=48,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True\n",
    "        )\n",
    "        \n",
    "        logits_ria = discriminator(input_ids=torch.LongTensor(inputs_ria['input_ids']).to(device).unsqueeze(0), \n",
    "                               attention_mask=torch.LongTensor(inputs_ria['attention_mask']).to(device).unsqueeze(0))[0][0]\n",
    "        pred_ria = torch.argmax(logits_ria).item()\n",
    "        \n",
    "        logits_lenta = discriminator(input_ids=torch.LongTensor(inputs_lenta['input_ids']).to(device).unsqueeze(0), \n",
    "                               attention_mask=torch.LongTensor(inputs_lenta['attention_mask']).to(device).unsqueeze(0))[0][0]\n",
    "        pred_lenta = torch.argmax(logits_lenta).item()\n",
    "        \n",
    "        if mode == 'HARD':\n",
    "            disc_ok += int(pred_ria == agency_to_discr_target['РИА Новости'] and \\\n",
    "                           pred_lenta == agency_to_discr_target['lenta.ru'])\n",
    "        elif mode == 'SOFT':\n",
    "            disc_ok += int(logits_ria[agency_to_discr_target['lenta.ru']] < \\\n",
    "                           logits_lenta[agency_to_discr_target['lenta.ru']])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "express-bubble",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.55"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(paired_discr_ok / 20, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "united-garage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.9"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(disc_ok / 20, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modular-search",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
