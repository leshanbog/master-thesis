{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sophisticated-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from transformers import BertTokenizer, EncoderDecoderModel, AutoModelForSequenceClassification\n",
    "\n",
    "\n",
    "from readers import tg_reader, lenta_reader, ria_reader\n",
    "from custom_datasets.agency_title_dataset import AgencyTitleDatasetGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beautiful-bronze",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_path = '/home/aobuhtijarov/models/rubert_cased_L-12_H-768_A-12_pt/'\n",
    "\n",
    "model_path = '/home/aobuhtijarov/models/style_gen_title_from_pretrained/checkpoint-6000/'\n",
    "discr_model_path = '/home/aobuhtijarov/models/agency_discriminator/checkpoint-4000/'\n",
    "\n",
    "test_data = '/home/aobuhtijarov/datasets/telegram_news/ru_tg_0511_0517.jsonl'\n",
    "lenta_path = '/home/aobuhtijarov/datasets/lenta/lenta-ru-news.test.csv'\n",
    "ria_path = '/home/aobuhtijarov/datasets/ria/ria.shuffled.test.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "innocent-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(tokenizer_path, do_lower_case=False, do_basic_tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "normal-kenya",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EncoderDecoderModel.from_pretrained(model_path)\n",
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hairy-failing",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = AutoModelForSequenceClassification.from_pretrained(discr_model_path)\n",
    "discriminator.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "municipal-story",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "120050it [01:17, 1541.12it/s]\n",
      "75925it [00:02, 30571.63it/s]\n",
      "47440it [00:29, 1601.41it/s]\n"
     ]
    }
   ],
   "source": [
    "test_records = [r for r in tqdm.tqdm(tg_reader(test_data))]\n",
    "lenta_records = [r for r in tqdm.tqdm(lenta_reader(lenta_path))]\n",
    "ria_records = [r for r in tqdm.tqdm(ria_reader(ria_path))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "organizational-station",
   "metadata": {},
   "outputs": [],
   "source": [
    "agency_list = [\"РИА Новости\", \"lenta.ru\"]\n",
    "agency_to_special_token_id = {a: tokenizer.vocab[f'[unused{i+1}]'] for i, a in enumerate(agency_list)}\n",
    "agency_to_discr_target = {a: i for i, a in enumerate(sorted(agency_list))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "pressing-default",
   "metadata": {},
   "outputs": [],
   "source": [
    "ria_data = AgencyTitleDatasetGeneration(ria_records, tokenizer, filter_agencies=None,\n",
    "                                        agency_to_special_token_id=agency_to_special_token_id)\n",
    "\n",
    "lenta_data = AgencyTitleDatasetGeneration(lenta_records, tokenizer, filter_agencies=None, \n",
    "                                          agency_to_special_token_id=agency_to_special_token_id)\n",
    "\n",
    "other_data = AgencyTitleDatasetGeneration(test_records, tokenizer, \n",
    "                                          filter_agencies=['Невские Новости', 'ФедералПресс', 'Dynamomania.com'], \n",
    "                                          agency_to_special_token_id=agency_to_special_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "backed-person",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47440, 75925, 1946)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ria_data), len(lenta_data), len(other_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "boolean-albania",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_on_dataset(dataset, target_agency, n=1000, max_tokens_title=48):\n",
    "    y_pred = []\n",
    "\n",
    "\n",
    "    for i in tqdm.tqdm(np.random.choice(len(dataset), n, replace=False), total=n):\n",
    "        x = dataset[i]\n",
    "        x['input_ids'][1] = agency_to_special_token_id[target_agency]\n",
    "\n",
    "        gen_ids = model.generate(\n",
    "            input_ids=x['input_ids'].cuda().unsqueeze(0),\n",
    "            attention_mask=x['attention_mask'].cuda().unsqueeze(0),\n",
    "            decoder_start_token_id=model.config.decoder.pad_token_id,\n",
    "            min_length=7,\n",
    "            max_length=20,\n",
    "            num_beams=6\n",
    "        )\n",
    "        \n",
    "        gen_title = [tokenizer.decode(x, skip_special_tokens=True) for x in gen_ids][0]\n",
    "        \n",
    "        inp = tokenizer(gen_title, \n",
    "            add_special_tokens=True, max_length=max_tokens_title,\n",
    "            padding='max_length', truncation=True\n",
    "        )\n",
    "\n",
    "        logits = discriminator(input_ids=torch.LongTensor(inp['input_ids']).cuda().unsqueeze(0), \n",
    "                               attention_mask=torch.LongTensor(inp['attention_mask']).cuda().unsqueeze(0))[0]\n",
    "        y_pred.append(torch.argmax(logits).item())\n",
    "    \n",
    "    return y_pred.count(agency_to_discr_target[target_agency]) / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-picnic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "expected-poster",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_title(input_ids, attention_mask):\n",
    "    gen_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        decoder_start_token_id=model.config.decoder.pad_token_id,\n",
    "        min_length=7,\n",
    "        max_length=22,\n",
    "        num_beams=6\n",
    "    )\n",
    "    \n",
    "    print(gen_ids)\n",
    "\n",
    "    gen_title = [tokenizer.decode(x, skip_special_tokens=True) for x in gen_ids][0]\n",
    "    return gen_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "comparable-frontier",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens_title = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "laden-burning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lenta.ru': 0, 'РИА Новости': 1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agency_to_discr_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "determined-entrepreneur",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0, 20622, 42873, 96388,  6188, 45206, 34124, 16327, 12938,  1650,\n",
      "         27453,   131, 17407, 29079, 17609, 24461,   102,   102,   102,   102,\n",
      "           102,   102]], device='cuda:0')\n",
      "Gen: адвокат емельяненко допустил оспаривание решения об условно-досрочном освобождении\n",
      "Ref: адвокат потерпевшей рассказал о возможном оспаривании удо александра емельяненко\n",
      "Gen: 0\n",
      "Ref: 0\n"
     ]
    }
   ],
   "source": [
    "n = random.randint(0, 43000)\n",
    "n = 11306\n",
    "# n=1186\n",
    "x = lenta_data[n]\n",
    "a = gen_title(x['input_ids'].cuda().unsqueeze(0), x['attention_mask'].cuda().unsqueeze(0))\n",
    "b = lenta_records[n]['title']\n",
    "print('Gen:', a)\n",
    "print('Ref:', b)\n",
    "\n",
    "inp = tokenizer(a, \n",
    "    add_special_tokens=True, max_length=max_tokens_title,\n",
    "    padding='max_length', truncation=True\n",
    ")\n",
    "\n",
    "logits = discriminator(input_ids=torch.LongTensor(inp['input_ids']).cuda().unsqueeze(0), \n",
    "                       attention_mask=torch.LongTensor(inp['attention_mask']).cuda().unsqueeze(0))[0]\n",
    "a_pred = torch.argmax(logits).item()\n",
    "\n",
    "inp = tokenizer(b, \n",
    "    add_special_tokens=True, max_length=max_tokens_title,\n",
    "    padding='max_length', truncation=True\n",
    ")\n",
    "\n",
    "logits = discriminator(input_ids=torch.LongTensor(inp['input_ids']).cuda().unsqueeze(0), \n",
    "                       attention_mask=torch.LongTensor(inp['attention_mask']).cuda().unsqueeze(0))[0]\n",
    "b_pred = torch.argmax(logits).item()\n",
    "\n",
    "print('Gen:', a_pred)\n",
    "print('Ref:', b_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "large-continent",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [06:09<00:00,  2.71it/s]\n",
      "100%|██████████| 1000/1000 [06:15<00:00,  2.67it/s]\n",
      "100%|██████████| 1000/1000 [06:13<00:00,  2.68it/s]\n",
      "100%|██████████| 1000/1000 [06:27<00:00,  2.58it/s]\n",
      "100%|██████████| 1000/1000 [06:24<00:00,  2.60it/s]\n",
      "100%|██████████| 1000/1000 [06:27<00:00,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37min 58s, sys: 8.07 s, total: 38min 6s\n",
      "Wall time: 37min 57s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "result = defaultdict(list)\n",
    "\n",
    "for i, data in enumerate((ria_data, lenta_data, other_data)):\n",
    "    for target_a in agency_list:\n",
    "        acc = eval_on_dataset(data, target_a)\n",
    "        result[i].append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acute-validity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>РИА Новости</th>\n",
       "      <th>lenta.ru</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RIA</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenta</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Other</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Data  РИА Новости  lenta.ru\n",
       "0    RIA        0.935     0.054\n",
       "1  Lenta        0.426     0.609\n",
       "2  Other        0.808     0.207"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['Data'] + agency_list)\n",
    "\n",
    "for i, dataset_name in enumerate(('RIA', 'Lenta', 'Other')):\n",
    "    row = {'Data': dataset_name}\n",
    "    for j, a in enumerate(agency_list):\n",
    "        row[a] = result[i][j]      \n",
    "    df = df.append(row, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "necessary-novelty",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = df.Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bright-career",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Data', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "annual-darwin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>РИА Новости</th>\n",
       "      <th>lenta.ru</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RIA</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lenta</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       РИА Новости  lenta.ru\n",
       "Data                        \n",
       "RIA           0.94      0.05\n",
       "Lenta         0.43      0.61\n",
       "Other         0.81      0.21"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-ending",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
