Главное:
* Метод сборки датасета, которые позволяет честно перенести стиль
* Метод автоматической оценки стиля
* Модели, доказуемо сохраняющие стиль
* Домен: заголовки, RU и EN

На выходе из экспериментов:
* 2 датасета: RU и EN, в каждом кластера по 2 СМИ, для EN возомжно больше
  * Сплиты этих датасетов (train/val/test)
* Модели для генерации заголовков в стиле разных СМИ для обоих языков
  * (Общий)(Lenta)(Lenta) и (Общий)(Ria)(Ria) ... -> Baseline, Single
  * (Cluster)(Все)(Lenta) и (Cluster)(Все)(Ria)... -> Single
  * (Общий)(Все)(Все) ... -> Baseline, Joint
  * (Cluster)(Все)(Все) ... -> Joint

Модели должны обучаться на одинаковом количестве данных

План:
* Достать код сборки "Общий" и "Cluster" и привести его в порядок (Лёша, 26 сентября)
* Найти датасеты для английского (Илья, 26 сентября)
* Написать код сборки для английского (Илья, 3 октября)
* Достать код обучения моделей и привести его в порядок (Лёша, 3 октября)
* Посмотреть на воркшопы LREC (Илья, 26 сентября)
* Набросать abstract для статьи (Илья + Лёша, 26 сентября)
* Related work (что делали в суммаризации и в симплификации в области контроллируемой генерации) (Илья + Лёша, 3 октября)
* Эксприементы с вырубанием дат в кластеризации
* Эксперименты с GPT-2
* Обучить модели для английского
* Написать всю статью


Дедлайн LREC: 10 января 2022
